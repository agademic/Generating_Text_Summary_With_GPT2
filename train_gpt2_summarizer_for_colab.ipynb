{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Copy of train_gpt2_summarizer.ipynb","provenance":[{"file_id":"https://github.com/agademic/Generating_Text_Summary_With_GPT2/blob/master/train_gpt2_summarizer.ipynb","timestamp":1599123416484}]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3f05e588239743c1bd35ca6d31fbc92c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_50b7e7905a9c4b5c9923a32888cba919","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8507906dd3f141c7a4c594dec1f0cc52","IPY_MODEL_8d7ffc736ae342cdaf2fbffb125d4f72"]}},"50b7e7905a9c4b5c9923a32888cba919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8507906dd3f141c7a4c594dec1f0cc52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_743da338e7fc4586970f0358c49dd0d2","_dom_classes":[],"description":"Epoch:   0%","_model_name":"FloatProgressModel","bar_style":"","max":5,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b7598eddf34943ccb3ec8a7b103093c1"}},"8d7ffc736ae342cdaf2fbffb125d4f72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9ac12dfe0f69434abd1fab745d35ed6e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/5 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a061f64c983f4e9f85a112ce3a47823a"}},"743da338e7fc4586970f0358c49dd0d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b7598eddf34943ccb3ec8a7b103093c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9ac12dfe0f69434abd1fab745d35ed6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a061f64c983f4e9f85a112ce3a47823a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d29763153754320bb8d13f5b719fac3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c1b2ada93016476c997df98480b5f5a9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ec1c84ffdb93492b8319178782f0ff45","IPY_MODEL_d145115738ea4332b9aa446afaef1562"]}},"c1b2ada93016476c997df98480b5f5a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec1c84ffdb93492b8319178782f0ff45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dc790a355c084d34939d97e75b55de22","_dom_classes":[],"description":"Training:   0%","_model_name":"FloatProgressModel","bar_style":"","max":3000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_274dade11ab943cbabfb9193e6a692ef"}},"d145115738ea4332b9aa446afaef1562":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b4295ab415c44a2c8fe9cb60cc4af118","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3000 [00:24&lt;9:34:27, 11.50s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1a375bd8b140485b98cc5e8535adc088"}},"dc790a355c084d34939d97e75b55de22":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"274dade11ab943cbabfb9193e6a692ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4295ab415c44a2c8fe9cb60cc4af118":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1a375bd8b140485b98cc5e8535adc088":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"4or4JN9FRpFC","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0JTe7ONJede","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1599122902007,"user_tz":-120,"elapsed":27122,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"a301c78a-5850-4f46-fefe-b07b4ca51879"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9SfmG1x8JyFc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599123004826,"user_tz":-120,"elapsed":901,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"75fa5790-a588-4349-a935-52e4837b58a3"},"source":["%cd gdrive/My Drive/GPT-2 Text Summarization/Generating_Text_Summary_With_GPT2"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/GPT-2 Text Summarization/Generating_Text_Summary_With_GPT2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3V7P7IcZKLgq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1599123018236,"user_tz":-120,"elapsed":1233,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"7fe44587-ab63-45ec-f3bd-9cbc74558019"},"source":["! ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["CNN\t\t\t    __pycache__\n","dataset.py\t\t    README.md\n","DM\t\t\t    requirements.txt\n","logs\t\t\t    train_gpt2_summarizer.ipynb\n","max_article_sizes.py\t    train_gpt2_summarizer_np.ipynb\n","output\t\t\t    train_gpt2_summarizer.py\n","play_with_summarizer.ipynb  utils.py\n","prepare_data.py\t\t    weights\n","prepare_np_data.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1dtK8qQ-KQkv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599123083460,"user_tz":-120,"elapsed":3343,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"edc931f4-b4d7-4bb6-9d95-b80213d19407"},"source":["!pip install tqdm"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OkszrAb_JgJz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599123093412,"user_tz":-120,"elapsed":6219,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["import argparse\n","from datetime import datetime\n","import json\n","import os\n","import pickle\n","import random\n","import time\n","\n","import numpy as np\n","from pytorch_transformers import ConstantLRSchedule, GPT2Config, GPT2LMHeadModel,AdamW, GPT2Tokenizer, WarmupLinearSchedule\n","from tensorboardX import SummaryWriter\n","import torch\n","from torch.nn import CrossEntropyLoss\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from tqdm import tnrange, tqdm_notebook\n","\n","from dataset import GPT21024Dataset \n","from utils import add_special_tokens, beam_search, generate_beam_sample, generate_sample, sample_seq, set_seed, top_k_top_p_filtering"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"4n-sYrYARpFK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1599123099213,"user_tz":-120,"elapsed":1125,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"c34d136f-11ce-4d63-a5df-c7e70e345149"},"source":["#please change default arguments if needed\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\"--lr\",default=5e-5, type=float, help=\"learning rate\")\n","parser.add_argument(\"--seed\",default=42, type=int,  help=\"seed to replicate results\")\n","parser.add_argument(\"--n_gpu\",default=1, type=int,  help=\"no of gpu available\")\n","parser.add_argument(\"--gradient_accumulation_steps\",default=32, type=int, help=\"gradient_accumulation_steps\")\n","parser.add_argument(\"--batch_size\",default=1, type=int,  help=\"batch_size\")\n","parser.add_argument(\"--num_workers\",default=4, type=int,  help=\"num of cpus available\")\n","parser.add_argument(\"--device\",default=torch.device('cuda'), help=\"torch.device object\")\n","parser.add_argument(\"--num_train_epochs\",default=5, type=int,  help=\"no of epochs of training\")\n","parser.add_argument(\"--output_dir\",default='./output', type=str,  help=\"path to save evaluation results\")\n","parser.add_argument(\"--model_dir\",default='./weights', type=str,  help=\"path to save trained model\")\n","parser.add_argument(\"--max_grad_norm\",default=1.0, type=float, help=\"max gradient norm.\")\n","parser.add_argument(\"--root_dir\",default='./CNN/gpt2_1024_data', type=str, help=\"location of json dataset.\")\n","parser.add_argument(\"--ids_file\",default='./CNN/ids.json', type=str, help=\"location of train, valid and test file indexes\")\n","args = parser.parse_args([])\n","print(args)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Namespace(batch_size=1, device=device(type='cuda'), gradient_accumulation_steps=32, ids_file='./CNN/ids.json', lr=5e-05, max_grad_norm=1.0, model_dir='./weights', n_gpu=1, num_train_epochs=5, num_workers=4, output_dir='./output', root_dir='./CNN/gpt2_1024_data', seed=42)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gxdl04kWRpFR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599123151413,"user_tz":-120,"elapsed":825,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def train(args, model, tokenizer, train_dataset, valid_dataset, ignore_index):\n","\n","    writer = SummaryWriter('./output/logs')\n","    train_sampler = RandomSampler(train_dataset)\n","    train_dl = DataLoader(train_dataset,sampler=train_sampler,batch_size=args.batch_size,num_workers=args.num_workers)\n","    loss_fct = CrossEntropyLoss(ignore_index=ignore_index) #ignores padding token for loss calculation\n","    optimizer = AdamW(model.parameters(),lr=args.lr)\n","    scheduler = WarmupLinearSchedule(optimizer,100,80000)\n","\n","    global_step = 0\n","    tr_loss, logging_loss = 0.0, 0.0\n","    model.zero_grad()\n","    train_iterator = tnrange(int(args.num_train_epochs), desc=\"Epoch\")\n","    set_seed(args)\n","    for _ in train_iterator:\n","        epoch_iterator = tqdm_notebook(train_dl, desc=\"Training\")\n","        for step, batch in enumerate(epoch_iterator):\n","            inputs, labels = torch.tensor(batch['article']), torch.tensor(batch['article'])\n","            inputs = inputs.to(args.device)\n","            labels = labels.to(args.device)\n","            model.train()\n","            logits = model(inputs)[0]\n","            idx = batch['sum_idx'].item() # index of separator token\n","            # only consider loss on reference summary just like seq2seq models\n","            shift_logits = logits[..., idx:-1, :].contiguous()\n","            shift_labels = labels[..., idx+1:].contiguous()\n","            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","            loss = loss/args.gradient_accumulation_steps\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n","            tr_loss += loss.item()\n","            if (step + 1) % args.gradient_accumulation_steps == 0:\n","                optimizer.step()\n","                scheduler.step()  # Update learning rate schedule\n","                model.zero_grad()\n","                global_step += 1\n","                writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n","                writer.add_scalar('loss', (tr_loss - logging_loss)/args.gradient_accumulation_steps, global_step)\n","                logging_loss = tr_loss\n","                print(\"loss:\", loss.item(), end='\\n\\n')\n","                if (step + 1)/args.gradient_accumulation_steps == 1.0:\n","                \tprint('After 1st update: ', end='\\n\\n')\n","                \tgenerate_sample(valid_dataset, tokenizer, model, num=2, eval_step=False)\n","                \n","                \n","            if (step + 1) % (10*args.gradient_accumulation_steps) == 0:\n","                results = evaluate(args, model, valid_dataset, ignore_index, global_step)\n","                for key, value in results.items():\n","                    writer.add_scalar('eval_{}'.format(key), value, global_step)\n","                print('After', global_step+1,'updates: ', end='\\n\\n')\n","                generate_sample(valid_dataset, tokenizer, model, num=2, eval_step=True)\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"gZYULPQmRpFW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599123291853,"user_tz":-120,"elapsed":893,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def evaluate(args, model, eval_dataset, ignore_index, global_step=None):\n"," \t# \"\"\" Returns perplexity score on validation dataset.\n"," \t# \tArgs:\n"," \t# \t\targs: dict that contains all the necessary information passed by user while training\n"," \t# \t\tmodel: finetuned gpt/gpt2 model\n"," \t# \t\teval_dataset: GPT21024Dataset object for validation data\n"," \t# \t\tglobal_step: no. of times gradients have backpropagated\n"," \t# \t\tignore_index: token not considered in loss calculation\n"," \t# \"\"\"\n","    if not os.path.exists(args.output_dir):\n","        os.mkdir(args.output_dir)\n","    eval_output_dir = args.output_dir\n","\n","    results = {}\n","    eval_sampler = SequentialSampler(eval_dataset)\n","    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.batch_size)\n","    loss_fct = CrossEntropyLoss(ignore_index=ignore_index) #ignores padding token for loss calculation\n","\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    model.eval()\n","\n","    for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n","        inputs, labels = torch.tensor(batch['article']).to(args.device), torch.tensor(batch['article']).to(args.device)\n","        \n","        with torch.no_grad():\n","            logits = model(inputs)[0]\n","            idx = batch['sum_idx'].item() # index of separator token\n","            # only consider loss on reference summary just like seq2seq models\n","            shift_logits = logits[..., idx:-1, :].contiguous()\n","            shift_labels = labels[..., idx+1:].contiguous()\n","            lm_loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","            eval_loss += lm_loss.mean().item()\n","        nb_eval_steps += 1\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    perplexity = torch.exp(torch.tensor(eval_loss))\n","\n","    result = {\n","        \"perplexity\": perplexity\n","    }\n","    print(\"perplexity:\", perplexity.item())\n","\n","    if global_step:\n","        output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n","        with open(output_eval_file, \"a\") as f:\n","\t        for key in sorted(result.keys()):\n","\t            f.write('\\n\\n')\n","\t            f.write(\"time = %s, %s = %s, step = %s\\n\" % (datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"), key, str(result[key]), str(global_step)))\n","    return result       "],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"m00kMA7NRpFc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1599123310077,"user_tz":-120,"elapsed":8322,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"9c766e66-4c6a-471f-f3b8-ae2ea8aaa4e8"},"source":["# creating training and validation dataset object\n","\n","train_data = GPT21024Dataset(args.root_dir,args.ids_file,mode='train',length=3000) #training on only 3000 datasets\n","valid_data = GPT21024Dataset(args.root_dir,args.ids_file,mode='valid',length=500)  #validation on only 500 datasets"],"execution_count":18,"outputs":[{"output_type":"stream","text":["100%|██████████| 1042301/1042301 [00:01<00:00, 950890.62B/s]\n","100%|██████████| 456318/456318 [00:00<00:00, 500192.98B/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gJjnSksWRpFg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599123379431,"user_tz":-120,"elapsed":65480,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"e8843776-b038-431f-d28d-8a5572d73c1b"},"source":["# load pretrained GPT2\n","tokenizer = add_special_tokens()\n","ignore_idx = tokenizer.pad_token_id\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","model.resize_token_embeddings(len(tokenizer))\n","model.to(args.device)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["100%|██████████| 665/665 [00:00<00:00, 249996.61B/s]\n","100%|██████████| 548118077/548118077 [00:42<00:00, 12990435.59B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50259, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"ZazfBcqCRpFl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":203,"referenced_widgets":["3f05e588239743c1bd35ca6d31fbc92c","50b7e7905a9c4b5c9923a32888cba919","8507906dd3f141c7a4c594dec1f0cc52","8d7ffc736ae342cdaf2fbffb125d4f72","743da338e7fc4586970f0358c49dd0d2","b7598eddf34943ccb3ec8a7b103093c1","9ac12dfe0f69434abd1fab745d35ed6e","a061f64c983f4e9f85a112ce3a47823a","2d29763153754320bb8d13f5b719fac3","c1b2ada93016476c997df98480b5f5a9","ec1c84ffdb93492b8319178782f0ff45","d145115738ea4332b9aa446afaef1562","dc790a355c084d34939d97e75b55de22","274dade11ab943cbabfb9193e6a692ef","b4295ab415c44a2c8fe9cb60cc4af118","1a375bd8b140485b98cc5e8535adc088"]},"outputId":"f72001a2-8df0-4ac4-d9e2-6fbc40d63cce"},"source":["#training the model\n","\n","start = time.time()\n","train(args, model, tokenizer, train_data, valid_data, ignore_idx)\n","print('total time: ', (time.time()-start)/60, \" minutes\", end='\\n\\n')\n","\n","print('Saving trained model...')\n","model_file = os.path.join(args.model_dir, 'model_data{}_trained_after_{}_epochs_only_sum_loss_ignr_pad.bin'.format(len(train_data),args.num_train_epochs))\n","config_file = os.path.join(args.model_dir, 'config_data{}_trained_after_{}_epochs_only_sum_loss_ignr_pad.json'.format(len(train_data),args.num_train_epochs))\n","torch.save(model.state_dict(), model_file)\n","model.config.to_json_file(config_file)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n","  del sys.path[0]\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f05e588239743c1bd35ca6d31fbc92c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch', max=5.0, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  app.launch_new_instance()\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d29763153754320bb8d13f5b719fac3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Training', max=3000.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"}]}]}